{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ac6b10-6849-493e-a3b9-410381a04c09",
   "metadata": {},
   "source": [
    "# Tarefa 1 — AdaBoost\n",
    "\n",
    "## 1) Cinco diferenças entre Random Forest e AdaBoost\n",
    "\n",
    "1. **Estratégia do ensemble**\n",
    "   - **Random Forest (RF):** usa *bagging* (amostragem bootstrap + média/votação).\n",
    "   - **AdaBoost:** usa *boosting* (modelos em sequência, cada novo modelo tenta corrigir erros do anterior).\n",
    "\n",
    "2. **Treinamento dos modelos**\n",
    "   - **RF:** árvores são treinadas **em paralelo** e de forma independente.\n",
    "   - **AdaBoost:** modelos são treinados **em série** (um depende do resultado do anterior).\n",
    "\n",
    "3. **Peso das amostras**\n",
    "   - **RF:** amostras tendem a ter “peso igual” (o bootstrap muda a amostra por sorteio).\n",
    "   - **AdaBoost:** aumenta o **peso** das amostras erradas para forçar o próximo modelo a focar nelas.\n",
    "\n",
    "4. **Seleção de variáveis (features)**\n",
    "   - **RF:** em cada split, a árvore avalia um **subconjunto aleatório de features** (`max_features`), aumentando diversidade.\n",
    "   - **AdaBoost:** a diversidade vem principalmente do **re-peso das amostras** e do `learning_rate` (não depende de `max_features` como pilar principal).\n",
    "\n",
    "5. **Robustez a ruído/outliers**\n",
    "   - **RF:** costuma ser mais robusto a ruído e outliers.\n",
    "   - **AdaBoost:** pode ser mais sensível a ruído/outliers, pois tende a “perseguir” exemplos difíceis (reponderados).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) O que é AdaBoost (resumo do método)\n",
    "\n",
    "AdaBoost (*Adaptive Boosting*) é um método de ensemble que combina vários modelos fracos (geralmente *stumps*, árvores rasas) para formar um modelo forte.  \n",
    "A ideia é simples: treinamos um primeiro modelo, avaliamos onde ele erra e, na próxima rodada, aumentamos a importância (peso) das amostras erradas. Repetimos isso por várias rodadas e, no final, combinamos os modelos com pesos (modelos que performam melhor tendem a “contar mais” na decisão final).\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Exemplo do AdaBoost em Python (baseado no exemplo do Scikit-learn)\n",
    "\n",
    "Nesta parte, foi utilizado o dataset `load_iris`, com separação treino/teste, treino do `AdaBoostClassifier` (com estimador base simples) e avaliação por métricas como acurácia, relatório de classificação e matriz de confusão.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Cinco hiperparâmetros importantes no AdaBoost\n",
    "\n",
    "1. **`n_estimators`**  \n",
    "   Quantidade de modelos (rodadas de boosting). Mais modelos podem melhorar desempenho, mas aumentam custo e risco de overfitting.\n",
    "\n",
    "2. **`learning_rate`**  \n",
    "   Controla o “tamanho do passo” do boosting. Valores menores reduzem a contribuição de cada modelo e podem exigir mais estimators.\n",
    "\n",
    "3. **`estimator` (ou `base_estimator`, dependendo da versão)**  \n",
    "   Define o modelo fraco usado em cada rodada (comum: `DecisionTreeClassifier(max_depth=1)`).\n",
    "\n",
    "4. **`algorithm`** *(quando disponível / dependendo da versão)*  \n",
    "   Estratégia do boosting (ex.: SAMME, SAMME.R). Afeta como os pesos e probabilidades são combinados.\n",
    "\n",
    "5. **`random_state`**  \n",
    "   Garante reprodutibilidade (muito útil para comparar resultados e entregar a atividade com consistência).\n",
    "\n",
    "> **Observação:** além desses, os hiperparâmetros do estimador base (ex.: `max_depth`, `min_samples_leaf`) também impactam bastante.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) GridSearch para melhores hiperparâmetros (load_iris) *(opcional)*\n",
    "\n",
    "Como extra, foi aplicado `GridSearchCV` para testar combinações de hiperparâmetros (ex.: `n_estimators`, `learning_rate` e parâmetros do estimador base), retornando `best_params_`, `best_score_` (validação cruzada) e a performance final no conjunto de teste.\n",
    "\n",
    "## 6) Exemplo do AdaBoost em Python (baseado no exemplo do Scikit-learn)\n",
    "\n",
    "### 6.1 Importações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9bf0f-2443-4148-b256-eb6b3bf8c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1abb9b-4bee-4bac-a0fc-a67fdbd7e9af",
   "metadata": {},
   "source": [
    "## 6.2 Carregar base (load_iris) e visualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0425a25-70d8-43c1-981c-713fc11406ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do df: (150, 5)\n",
      "Colunas: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris(as_frame=True)\n",
    "\n",
    "df = data.frame.copy()\n",
    "print(\"Shape do df:\", df.shape)\n",
    "print(\"Colunas:\", df.columns.tolist())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ba05e-a01e-4fb0-923e-28fa10dc17ad",
   "metadata": {},
   "source": [
    "## 6.3 Separar X e y + train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25dab313-b99c-49e4-bcf4-b5067ddd03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (105, 4) Teste: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "target = \"target\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b44e26-4bff-4128-b163-9d68f90b103e",
   "metadata": {},
   "source": [
    "## 6.4 Treinar AdaBoost\n",
    "\n",
    "Boas práticas: usar um estimador fraco como base (ex.: árvore rasa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8b65b2-8ff9-4581-b034-5db3171bfcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia (AdaBoost): 0.9333\n"
     ]
    }
   ],
   "source": [
    "base = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "\n",
    "adb = AdaBoostClassifier(\n",
    "    estimator=base,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adb.fit(X_train, y_train)\n",
    "y_pred = adb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia (AdaBoost): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea250f3-9f7f-4b62-99b7-8fda6b18646b",
   "metadata": {},
   "source": [
    "## 6.5 Relatório e Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e96ad40-e921-4f58-8afc-884f5234dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.88      0.93      0.90        15\n",
      "           2       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n",
      "\n",
      "Matriz de confusão:\n",
      " [[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  2 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatriz de confusão:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a91b74-7677-4eb7-b204-74104a4f39e4",
   "metadata": {},
   "source": [
    "## 6.6 Resumo (y_real vs y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c306ca88-f263-4492-97bf-e3b7312be17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas no resumo: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_real  y_pred\n",
       "0       2       2\n",
       "1       1       1\n",
       "2       2       1\n",
       "3       1       1\n",
       "4       2       2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame({\n",
    "    \"y_real\": y_test.reset_index(drop=True),\n",
    "    \"y_pred\": pd.Series(y_pred)\n",
    "})\n",
    "\n",
    "print(\"Linhas no resumo:\", len(res))\n",
    "res.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f921c-620d-4a1a-aa02-3fe2b1c7f4de",
   "metadata": {},
   "source": [
    "## 7) GridSearch para melhores hiperparâmetros (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbd9270-c096-4cfe-8e56-13f1f150b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'estimator__max_depth': 1, 'learning_rate': 0.05, 'n_estimators': 400}\n",
      "Melhor score (CV): 0.9619047619047618\n",
      "Acurácia no teste (melhor modelo): 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "adb = AdaBoostClassifier(\n",
    "    estimator=base,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 400],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    \"estimator__max_depth\": [1, 2, 3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=adb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", gs.best_params_)\n",
    "print(\"Melhor score (CV):\", gs.best_score_)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "y_pred_gs = best_model.predict(X_test)\n",
    "\n",
    "acc_gs = accuracy_score(y_test, y_pred_gs)\n",
    "print(f\"Acurácia no teste (melhor modelo): {acc_gs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2faa31-8aa7-41d4-83dd-8d4ac0429fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PrevisaoVenda)",
   "language": "python",
   "name": "previsaovenda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
